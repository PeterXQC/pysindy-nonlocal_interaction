{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator(x, intervals):\n",
    "    '''\n",
    "Define the indicator function\n",
    "     indicator function is function which if x value is inside the bound, you will get 1\n",
    "     Otherwise you will get 0\n",
    "     \n",
    "Require:\n",
    "    x, left_bound, right_bound must have the same dimension\n",
    "\n",
    "Parameters: \n",
    "    \n",
    "        x: 1 x n vector representing the point to check (Time dimension should be excluded)\n",
    "\n",
    "        intervals: 2d (n x 2) arrays. First dimension is all the  spatial dimensions, and second dimension are \n",
    "                left and right bound of the subdomain\n",
    "    \n",
    "`return: \n",
    "        1 or 0, should be clear enough\n",
    "    \n",
    "    '''\n",
    "    if len(x) != len(len(intervals[:, 0])):\n",
    "        raise ValueError(\"Parameter dimensions do not agree.\")\n",
    "        \n",
    "    for i in np.arange(len(intervals[:, 0])):\n",
    "        if x[i] < intervals[i, 0] or x > intervals[i, 1]:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integral(X, grid_ndim, num_x, j, endpts):\n",
    "    '''\n",
    "    Parameters: \n",
    "    \n",
    "        X: data grid\n",
    "        \n",
    "        grid_ndim: number of spatial dimensions. this is already a param in pysindy\n",
    "        \n",
    "        num_x: number of spatial datapoints in the grid.\n",
    "        \n",
    "        j: feature index\n",
    "        \n",
    "        endpts: 2 x n array \n",
    "            the first column is the left endpoints of the subdomain's each of the n dimensions,\n",
    "            second column is right endpoint of each of the subdomain's each of the n dimensions\n",
    "            \n",
    "    return:\n",
    "        nd integral within a subdomain\n",
    "    '''  \n",
    "# find weights\n",
    "#     All the 1D weights will be stored in a 2D matrix as cols\n",
    "#     sudo_var1: max number of pts per dim.\n",
    "    weights = []\n",
    "    for i in np.arange(grid_ndim):\n",
    "#         here create the index s\n",
    "        index = [0]*grid_ndim\n",
    "        index[i] = slice(None)\n",
    "        index[-1] = i\n",
    "        \n",
    "#         we now get the 1D grid by filtering by the index created\n",
    "        this_dim = spatiotemporal_grid[index]\n",
    "        \n",
    "        weight = get_1D_weight(this_dim, endpts[:, i])\n",
    "#         append is extremely slow, but since its only used grid_ndim times it shouldn't bottle neck.\n",
    "        weights.append(weight)\n",
    "    \n",
    "    W_F = get_full_weight(weights)\n",
    "    \n",
    "# We now construct \n",
    "#     filter by feature first as feature is itself a dimension\n",
    "#         get the j-th column, which is the j-th freature of all datapoints.\n",
    "    X_j = X[:, j]\n",
    "#         We now filter by t, the double colons take every num_t-th element of x_j.\n",
    "    X_tj = X_j[this_t::num_t]\n",
    "\n",
    "#     need to double check the waus x_1, ..., x_n is ordered to see how to reshape. \n",
    "    X_mat = np.reshape(X_tj, np.shape(W_F))\n",
    "    \n",
    "#     NEED TO FILTER BY X HERE FINALLY, TO GET F.\n",
    "\n",
    "#     find F, which is all the data points in this subdomain.\n",
    "integral = np.sum(np.dot(W_F, F))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_weight(weights):\n",
    "    '''\n",
    "    weights: a list of lists, where each inner list is the 1D weight in a dimension. \n",
    "    '''\n",
    "    ndim = len(weights)\n",
    "    W_F = np.array(weights[0])\n",
    "    for w in np.arange(ndim-1)+1:\n",
    "        index = [slice(None)]*(w+1)\n",
    "        index[-1] = np.newaxis\n",
    "\n",
    "        W_F = W_F[index] * np.array(weights[w])\n",
    "    return W_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u_j(x, num_x, t, j):\n",
    "    '''\n",
    "    x: data value x', a constant after stacking.\n",
    "    t: time point t\n",
    "    j: the feature of u that will get returned.\n",
    "    '''  \n",
    "#     spatial-temporal stack index\n",
    "    ind = x*num_x+t\n",
    "    \n",
    "#   X is 2D, \n",
    "    return X[ind, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1D_weight(grid, endpt):\n",
    "    '''\n",
    "    Parameters: \n",
    "        grid: an 1D array that contains the value of the corresponding dimension of each grid points.\n",
    "        \n",
    "        endpt: \n",
    "    '''\n",
    "    \n",
    "#     initialize a bunch of 0\n",
    "    weight = np.zeros(len(grid))\n",
    "\n",
    "#     find the index at which we enter Omega_k in this axis\n",
    "    start = 0\n",
    "    end = 0\n",
    "    record_start = True\n",
    "    record_end = True\n",
    "    for i in np.arange(len(grid)):\n",
    "        if (grid[i] >= endpt[0] and record_start == True):\n",
    "            start = i\n",
    "            record_start = False\n",
    "        if (grid[i] >= endpt[1] and record_end == True):\n",
    "            end = i\n",
    "            record_end = False\n",
    "            \n",
    "#     the weight of all other grid points is 0 as they contribute nothing to the integral\n",
    "#     and each grid point in omega_k needs a weight\n",
    "\n",
    "#     start and end index has different equation for weight, so we do those first\n",
    "    weight[start] = 1/2*(grid[start+1]-grid[start])\n",
    "    weight[end] = 1/2*(grid[end]-grid[end-1])\n",
    "    for i in np.arange(end-start-1): \n",
    "        weight[start+i+1] = 1/2*(grid[start+i+2]-grid[start+i])\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u_j(x, num_x, t, j):\n",
    "    '''\n",
    "    x: data value x', a constant after stacking.\n",
    "    t: time point t\n",
    "    j: the feature of u that will get returned.\n",
    "    '''  \n",
    "#     spatial-temporal stack index\n",
    "    ind = x*num_x+t\n",
    "    \n",
    "#   X is 2D, \n",
    "    return X[ind, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omega_bound(index, intervals):\n",
    "    '''\n",
    "    Parameter:\n",
    "        index: index of the subdomain to get bound of\n",
    "        intervals: boundary of each subdomain correspond to each dimension\n",
    "        \n",
    "    return:\n",
    "        2d (n x 2) arrays. First dimension is all the  spatial dimensions, and second dimension are left and right bound of the subdomain\n",
    "    '''\n",
    "    \n",
    "    return intervals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_nonloc(j, k, kprime, intervals):\n",
    "#     get how many time points are there\n",
    "    num_t = np.shape(spatiotemporal_grid)[-2]\n",
    "#     get how many spatial points are there\n",
    "    num_x = np.prod(np.shape(spatiotemporal_grid)[:-2])\n",
    "    \n",
    "    theta_nonloc_p = np.zeros(num_t*num_x)\n",
    "    \n",
    "    for i in np.arange(theta_nonloc_p.length):\n",
    "        this_t = i % num_t\n",
    "        this_x = int(i/num_t)\n",
    "        \n",
    "#       get x(all x, this_t)\n",
    "#       This currently filters the spatial temporal grid, as opposed to X\n",
    "#       We mat not need this though, as we can use num_t and num_x to figure out the stacking of X.\n",
    "#         n_dims  = len(np.shape(spatiotemporal_grid))\n",
    "#         s = [slice(None) for i in range(n_dims)]\n",
    "#         s[-2] = this_t\n",
    "#         grid_t = spatiotemporal_grid[tuple(s)]\n",
    "        \n",
    "        coefficient = indicator(this_x, get_omega_bound(k, intervals))\n",
    "        \n",
    "        integral = compute_integral(this_x, this_t, num_x, j, get_omega_bound(kprime, intervals), X)\n",
    "        \n",
    "        theta_nonloc_p[i] = coefficient * integral\n",
    "        \n",
    "    return theta_nonloc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(*args):\n",
    "    return np.sum(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the session where we test each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "  7.   7.5  8.   8.5  9.   9.5 10. ]\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.5  0.25 0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "# 1D weight test starts here. \n",
    "sample_grid = np.linspace(0, 10, 21, endpoint=True)\n",
    "endpts = [4, 5]\n",
    "print(sample_grid)\n",
    "print(get_1D_weight(sample_grid, endpts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above cell shows that the 1D weight calculation is performing properly. We now test the computation to get the full weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "# test using a 4D weight, formatted as the output of  \n",
    "test_weights = [[1,5,7,45],[1,6,8],[45,7],[3,5,7,8,2,65,78,89]]\n",
    "W_F = get_full_weight(test_weights)\n",
    "\n",
    "# Goal: W_F[x, y,..., a] = test_weights[0][x]*test_weights[1][y]*...*test_weights[-1][a]\n",
    "\n",
    "# for this test, we will just use a stacked for loop to make sure we are computing the right value. Generality is put aside for now.\n",
    "for x in range(len(test_weights[0])):\n",
    "    for y in range(len(test_weights[1])):\n",
    "        for z in range(len(test_weights[2])):\n",
    "            for a in range(len(test_weights[3])):\n",
    "                if W_F[x, y, z, a] != test_weights[0][x]*test_weights[1][y]*test_weights[2][z]*test_weights[3][a]:\n",
    "                    print(\"Failed\")\n",
    "                    break\n",
    "print(\"Pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now test the part where we filter data points in a subdomain out of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-ab1aeb013953>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ab1aeb013953>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    integral = np.sum(np.dot(W_F, F))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# filter by feature first as feature is itself a dimension\n",
    "#     get the j-th column, which is the j-th freature of all datapoints.\n",
    "X_j = X[:, j]\n",
    "#     We now filter by t, the double colons take every num_t-th element of x_j.\n",
    "X_tj = X_j[this_t::num_t]\n",
    "\n",
    "# need to double check the waus x_1, ..., x_n is ordered to see how to reshape. \n",
    "X_mat = np.reshape(X_tj, np.shape(W_F))\n",
    "\n",
    "# find F, which is all the data points in this subdomain.\n",
    "    integral = np.sum(np.dot(W_F, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: To filter by time after filter by feature j, our X_j would look something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 0. 1. 2. 3. 4. 0. 1. 2. 3. 4. 0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "X = np.linspace(0, 19, 20)%5\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, this_t is the t we want to filter out, and num_t is the number of different time points there are. So, if we do the filtering below, we would obtain all the instances of this_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., 3.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_t = 3\n",
    "num_t = 5\n",
    "\n",
    "X[this_t::num_t]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "043433d6b18bdeb8544c06540320f4c494e406f840db1fa6d3d1188f7786a55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
