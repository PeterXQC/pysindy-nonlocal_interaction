{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f25006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "import numpy as np\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14e271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator(x, endpts):\n",
    "    '''\n",
    "Definition:\n",
    "     indicator function is function which if x value is inside the bound, you will get 1\n",
    "     Otherwise you will get 0\n",
    "     \n",
    "Require:\n",
    "    x, left_bound, right_bound must have the same dimension\n",
    "\n",
    "Parameters: \n",
    "    \n",
    "        x: 1 x n vector representing the index of point to check (Time dimension should be excluded)\n",
    "\n",
    "        endpts: 2d (n x 2) array of index. First dimension is all the spatial dimensions, and second dimension are \n",
    "                left and right bound of the subdomain in terms of index\n",
    "    \n",
    "`return: \n",
    "        1 or 0, should be clear enough\n",
    "    \n",
    "    '''\n",
    "    if len(x) != len(len(endpts[:, 0])):\n",
    "        raise ValueError(\"Parameter dimensions do not agree.\")\n",
    "        \n",
    "    for i in np.arange(len(endpts[:, 0])):\n",
    "        if x[i] < endpts[i, 0] or x > endpts[i, 1]:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c13447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_integral(X, spatiotemporal_grid, t, j, endpts):\n",
    "    '''\n",
    "    Parameters: \n",
    "    \n",
    "        X: data grid\n",
    "        \n",
    "        spatiotemporal_grid: The spatiotemporal_grid that contains information about spatial and time data points.\n",
    "        \n",
    "        j: feature index\n",
    "        \n",
    "        endpts: n x 2 array \n",
    "            the first column is the left endpoints of the subdomain's each of the n dimensions in terms of index,\n",
    "            second column is right endpoint of each of the subdomain's each of the n dimensions in terms of index\n",
    "            \n",
    "    return:\n",
    "        nd integral within a subdomain\n",
    "    '''  \n",
    "    \n",
    "#     Since all the spatiotemporal_grid only contains time and spatial dimensions, and there must be 1 time dimension\n",
    "#     the number of spatial is then given as following\n",
    "    grid_ndim = len(np.shape(spatiotemporal_grid))-1\n",
    "    \n",
    "# find weights\n",
    "#     All the 1D weights will be stored in a 2D matrix as cols\n",
    "#     sudo_var1: max number of pts per dim.\n",
    "    weights = []\n",
    "    for i in np.arange(grid_ndim):\n",
    "#         +1 to account for the time dimension\n",
    "        index = [0]*(grid_ndim+1)\n",
    "        index[i] = slice(None)\n",
    "        index[-1] = i\n",
    "#         Time is always the second to last dimension, which is filtered here\n",
    "        index[-2] = t\n",
    "        \n",
    "#         we now get the 1D grid by filtering by the index created\n",
    "        this_dim = spatiotemporal_grid[index]\n",
    "        \n",
    "        weight = get_1D_weight(this_dim, endpts[i, :])\n",
    "        weights.append(weight)\n",
    "    \n",
    "    W_F = get_full_weight(weights)\n",
    "    \n",
    "# We now construct F, the spatial grid within a subdomain\n",
    "    X_F = retrieve_data_mat(spatiotemporal_grid, X)\n",
    "    F = filterX(X, j, endpts, t)\n",
    "\n",
    "    return np.sum(np.dot(W_F, F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1f4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix to obtain weight\n",
    "\n",
    "def get_1D_weight(grid, endpt):\n",
    "    '''\n",
    "    Parameters: \n",
    "        grid: an 1D array that contains the value of the corresponding dimension of each grid points.\n",
    "        \n",
    "        endpts: 1 x 2 array \n",
    "            the first element is the left endpoints of this dimensions in terms of index,\n",
    "            second element is the left endpoints of this dimensions in terms of index,\n",
    "    '''\n",
    "    \n",
    "#     initialize a bunch of 0\n",
    "    weight = np.zeros(len(grid))\n",
    "\n",
    "#     find the index at which we enter Omega_k in this axis\n",
    "    start = 0\n",
    "    end = 0\n",
    "    record_start = True\n",
    "    record_end = True\n",
    "    for i in np.arange(len(grid)):\n",
    "        if (grid[i] >= endpt[0] and record_start == True):\n",
    "            start = i\n",
    "            record_start = False\n",
    "        if (grid[i] >= endpt[1] and record_end == True):\n",
    "            end = i\n",
    "            record_end = False\n",
    "            \n",
    "#     the weight of all other grid points is 0 as they contribute nothing to the integral\n",
    "#     and each grid point in omega_k needs a weight\n",
    "\n",
    "#     start and end index has different equation for weight, so we do those first\n",
    "    weight[start] = 1/2*(grid[start+1]-grid[start])\n",
    "    weight[end] = 1/2*(grid[end]-grid[end-1])\n",
    "    for i in np.arange(end-start-1): \n",
    "        weight[start+i+1] = 1/2*(grid[start+i+2]-grid[start+i])\n",
    "    \n",
    "    return weight\n",
    "\n",
    "def get_full_weight(weights):\n",
    "    '''\n",
    "    weights: a list of lists, where each inner list is the 1D weight in a dimension. \n",
    "    '''\n",
    "    ndim = len(weights)\n",
    "    W_F = np.array(weights[0])\n",
    "    for w in np.arange(ndim-1)+1:\n",
    "        index = [slice(None)]*(w+1)\n",
    "        index[-1] = np.newaxis\n",
    "\n",
    "        W_F = W_F[index] * np.array(weights[w])\n",
    "    return W_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a06561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to filter data matrix X\n",
    "def retrieve_data_mat(spatiotemporal_grid, X):\n",
    "    overallShape = list(np.shape(spatiotemporal_grid)) + [np.shape(X)[-1]]\n",
    "    return X.reshape(overallShape)\n",
    "\n",
    "def filterX(X, j, bound, t_ind):\n",
    "#     filter by feature j first\n",
    "    index = [0]*len(np.shape(X))\n",
    "    for i in range(np.shape(bound)[0]):\n",
    "        index[i] = slice(bound[i][0], bound[i][1])\n",
    "    index[-2] = t_ind\n",
    "    index[-1] = j\n",
    "    return X[tuple(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b41ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_nonloc(spatiotemporal_grid, j, k, kprime, endpts):\n",
    "    '''\n",
    "    Parameters:\n",
    "        spatiotemporal_grid: The spatiotemporal_grid that contains information about spatial and time data points.\n",
    "        j: the index of u that we are looking for\n",
    "        k: the index of subdomain to be used by the indicator function\n",
    "        kprime: the index of the subdomain to be used as boundary of integral\n",
    "        endpts: boundary of each subdomain correspond to each dimension in terms of indexing. \n",
    "        \n",
    "    return: \n",
    "        vector Theta^nonloc_p\n",
    "    '''\n",
    "#     get how many time points are there\n",
    "    num_t = np.shape(spatiotemporal_grid)[-2]\n",
    "#     get how many spatial points are there\n",
    "    num_x = np.prod(np.shape(spatiotemporal_grid)[:-2])\n",
    "    \n",
    "    theta_nonloc_p = np.zeros(num_t*num_x)\n",
    "    \n",
    "    for i in np.arange(theta_nonloc_p.length):\n",
    "        this_t = i % num_t\n",
    "        this_x = int(i/num_t)\n",
    "        \n",
    "        coefficient = indicator(this_x, endpts[k])\n",
    "        \n",
    "        integral = compute_integral(X, spatiotemporal_grid, this_t, j, endpts[kprime])\n",
    "        \n",
    "        theta_nonloc_p[i] = coefficient * integral\n",
    "        \n",
    "    return theta_nonloc_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b47fa",
   "metadata": {},
   "source": [
    "# Module test starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf571258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5\n",
      "  7.   7.5  8.   8.5  9.   9.5 10. ]\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.5  0.25 0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "# 1D weight test starts here. \n",
    "sample_grid = np.linspace(0, 10, 21, endpoint=True)\n",
    "endpts = [4, 5]\n",
    "print(sample_grid)\n",
    "print(get_1D_weight(sample_grid, endpts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da032d",
   "metadata": {},
   "source": [
    "# The above cell shows that the 1D weight calculation is performing properly. We now test the computation to get the full weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7c291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "# test using a 4D weight, formatted as the output of  \n",
    "test_weights = [[1,5,7,45],[1,6,8],[45,7],[3,5,7,8,2,65,78,89]]\n",
    "W_F = get_full_weight(test_weights)\n",
    "\n",
    "# Goal: W_F[x, y,..., a] = test_weights[0][x]*test_weights[1][y]*...*test_weights[-1][a]\n",
    "\n",
    "# for this test, we will just use a stacked for loop to make sure we are computing the right value. Generality is put aside for now.\n",
    "for x in range(len(test_weights[0])):\n",
    "    for y in range(len(test_weights[1])):\n",
    "        for z in range(len(test_weights[2])):\n",
    "            for a in range(len(test_weights[3])):\n",
    "                if W_F[x, y, z, a] != test_weights[0][x]*test_weights[1][y]*test_weights[2][z]*test_weights[3][a]:\n",
    "                    print(\"Failed\")\n",
    "                    break\n",
    "print(\"Pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085447e3",
   "metadata": {},
   "source": [
    "# Reshape Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0206d4f4",
   "metadata": {},
   "source": [
    "Some interesting things I've found:\n",
    "\n",
    "    Out here we use A.reshape to reshape an array, and the transformation from our original matrix to 2D data matrix X is indeed simply A.reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to create a testing input X\n",
    "\n",
    "from typing import List\n",
    "from sklearn.base import TransformerMixin\n",
    "HANDLED_FUNCTIONS = {}\n",
    "\n",
    "class AxesArray(np.lib.mixins.NDArrayOperatorsMixin, np.ndarray):\n",
    "    \"\"\"A numpy-like array that keeps track of the meaning of its axes.\n",
    "\n",
    "    Paramters:\n",
    "        input_array (array-like): the data to create the array.\n",
    "        axes (dict): A dictionary of axis labels to shape indices.\n",
    "            Allowed keys:\n",
    "                - ax_time: int\n",
    "                - ax_coord: int\n",
    "                - ax_sample: int\n",
    "                - ax_spatial: List[int]\n",
    "\n",
    "    Raises:\n",
    "        AxesWarning if axes does not match shape of input_array\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(cls, input_array, axes):\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        defaults = {\n",
    "            \"ax_time\": None,\n",
    "            \"ax_coord\": None,\n",
    "            \"ax_sample\": None,\n",
    "            \"ax_spatial\": [],\n",
    "        }\n",
    "        if axes is None:\n",
    "            return obj\n",
    "        obj.__dict__.update({**defaults, **axes})\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj) -> None:\n",
    "        if obj is None:\n",
    "            return\n",
    "        self.ax_time = getattr(obj, \"ax_time\", None)\n",
    "        self.ax_coord = getattr(obj, \"ax_coord\", None)\n",
    "        self.ax_sample = getattr(obj, \"ax_sample\", None)\n",
    "        self.ax_spatial = getattr(obj, \"ax_spatial\", [])\n",
    "\n",
    "    @property\n",
    "    def n_spatial(self):\n",
    "        return tuple(self.shape[ax] for ax in self.ax_spatial)\n",
    "\n",
    "    @property\n",
    "    def n_time(self):\n",
    "        return self.shape[self.ax_time] if self.ax_time is not None else 1\n",
    "\n",
    "    @property\n",
    "    def n_sample(self):\n",
    "        return self.shape[self.ax_sample] if self.ax_sample is not None else 1\n",
    "\n",
    "    @property\n",
    "    def n_coord(self):\n",
    "        return self.shape[self.ax_coord] if self.ax_coord is not None else 1\n",
    "\n",
    "    def __array_ufunc__(\n",
    "        self, ufunc, method, *inputs, out=None, **kwargs\n",
    "    ):  # this method is called whenever you use a ufunc\n",
    "        args = []\n",
    "        for input_ in inputs:\n",
    "            if isinstance(input_, AxesArray):\n",
    "                args.append(input_.view(np.ndarray))\n",
    "            else:\n",
    "                args.append(input_)\n",
    "\n",
    "        outputs = out\n",
    "        if outputs:\n",
    "            out_args = []\n",
    "            for output in outputs:\n",
    "                if isinstance(output, AxesArray):\n",
    "                    out_args.append(output.view(np.ndarray))\n",
    "                else:\n",
    "                    out_args.append(output)\n",
    "            kwargs[\"out\"] = tuple(out_args)\n",
    "        else:\n",
    "            outputs = (None,) * ufunc.nout\n",
    "        results = super().__array_ufunc__(ufunc, method, *args, **kwargs)\n",
    "        if results is NotImplemented:\n",
    "            return NotImplemented\n",
    "        if method == \"at\":\n",
    "            return\n",
    "        if ufunc.nout == 1:\n",
    "            results = (results,)\n",
    "        results = tuple(\n",
    "            (AxesArray(np.asarray(result), self.__dict__) if output is None else output)\n",
    "            for result, output in zip(results, outputs)\n",
    "        )\n",
    "        return results[0] if len(results) == 1 else results\n",
    "\n",
    "    def __array_function__(self, func, types, args, kwargs):\n",
    "        if func not in HANDLED_FUNCTIONS:\n",
    "            arr = super(AxesArray, self).__array_function__(func, types, args, kwargs)\n",
    "            if isinstance(arr, np.ndarray):\n",
    "                return AxesArray(arr, axes=self.__dict__)\n",
    "            elif arr is not None:\n",
    "                return arr\n",
    "            return\n",
    "        if not all(issubclass(t, AxesArray) for t in types):\n",
    "            return NotImplemented\n",
    "        return HANDLED_FUNCTIONS[func](*args, **kwargs)\n",
    "    \n",
    "# This is how we created X from the original list of stuff, \n",
    "def concat_sample_axis(x_list: List[AxesArray]):\n",
    "    \"\"\"Concatenate all trajectories and axes used to create samples.\"\"\"\n",
    "    new_arrs = []\n",
    "    for x in x_list:\n",
    "        sample_axes = (\n",
    "            x.ax_spatial\n",
    "            + ([x.ax_time] if x.ax_time is not None else [])\n",
    "            + ([x.ax_sample] if x.ax_sample is not None else [])\n",
    "        )\n",
    "        \n",
    "#         print(sample_axes)\n",
    "        \n",
    "        new_axes = {\"ax_sample\": 0, \"ax_coord\": 1}\n",
    "        n_samples = np.prod([x.shape[ax] for ax in sample_axes])\n",
    "        \n",
    "#         print(n_samples)\n",
    "        \n",
    "#         the new 2D data matrix is literally created with a reshape\n",
    "#         print(x.reshape((n_samples, x.shape[x.ax_coord])))\n",
    "        arr = AxesArray(x.reshape((n_samples, x.shape[x.ax_coord])), new_axes)\n",
    "#         Actually, this is problematic. We only did a reshape without doing any filtering and stuff \n",
    "#         so we cannot guarantee each column is indeed a feature\n",
    "        \n",
    "#         and each 2D data matrix (for their corresponding trajectory) is put into a list. \n",
    "        new_arrs.append(arr)\n",
    "    return np.concatenate(new_arrs, axis=new_arrs[0].ax_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee138e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# space_1, space_2, t, coord(feature)\n",
    "# We carry the assumption that the first d-2 axis are spatial, second last is time, and last is coords. \n",
    "A = np.random.rand(12, 13, 7, 2)\n",
    "axes = {\"ax_spatial\": [0, 1], \"ax_time\": 2, \"ax_coord\": 3}\n",
    "A_ = AxesArray(A, axes)\n",
    "\n",
    "# need brackets around A_ as input is list of trajectories\n",
    "A_2 = concat_sample_axis([A_])\n",
    "\n",
    "# indeed, an reshape retrieves the original matrix.\n",
    "np.linalg.norm(A_2.reshape(A.shape)-A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad3401",
   "metadata": {},
   "source": [
    "# We now test the part where we filter data points in a subdomain out of X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130282d",
   "metadata": {},
   "source": [
    "### We carry the assumption that the first d-2 axis are spatial, second last is time, and last is coords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c59fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Construct a sample input for our program.\n",
    "data = loadmat('pysindy-master/examples/data/burgers.mat')\n",
    "time = np.ravel(data['t'])\n",
    "x = np.ravel(data['x'])\n",
    "time = np.ravel(data['t'])\n",
    "X, T = np.meshgrid(x, time)\n",
    "\n",
    "axes = {\"ax_spatial\": [0], \"ax_time\": 1, \"ax_coord\": 2}\n",
    "A = AxesArray(np.asarray([X, T]).T, axes)\n",
    "\n",
    "# Here we only care about the size of the grid, which will match the size of A without the feature axis.\n",
    "# spatiotemporal_grid is a parameter of our program\n",
    "spatiotemporal_grid = np.zeros(np.shape(np.asarray([X, T]).T)[0:-1])\n",
    "\n",
    "# A_ is a parameter of our program\n",
    "A_ = concat_sample_axis([A])\n",
    "\n",
    "Data = retrieve_data_mat(spatiotemporal_grid, A_)\n",
    "\n",
    "print(np.linalg.norm(Data-A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064c04c",
   "metadata": {},
   "source": [
    "### With Data matrix retrieved, we now filter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f06c87d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# We want the first feature\n",
    "j = 0\n",
    "# We want the 50-th time point\n",
    "t_ind = 50\n",
    "# The subdomain is bounded by the 10-th and 20-th point. We only have 1D but if we have more dimensions, \n",
    "# x_bound is expected to be a list of list, with bounds of each spatial dimensions in order.\n",
    "x_bound = [[10, 20]]\n",
    "\n",
    "Expected = np.asarray([X, T]).T[x_bound[0][0]:x_bound[0][1], 50, 0]\n",
    "\n",
    "obtained = filterX(Data, j, x_bound, t_ind)\n",
    "\n",
    "print(np.linalg.norm(Expected - obtained))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e713a48",
   "metadata": {},
   "source": [
    "# Moment of Truth: Test integral calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d1fbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "u = np.real(data['usol'])\n",
    "rmse = mean_squared_error(u, np.zeros(u.shape), squared=False)\n",
    "u = u + np.random.normal(0, rmse / 5.0, u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3030cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 101)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb1fe330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 101, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacePts = np.shape(np.asarray([X, T]).T)[0]\n",
    "timePts = np.shape(np.asarray([X, T]).T)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4919d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_integral(X, spatiotemporal_grid, t, j, endpts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "043433d6b18bdeb8544c06540320f4c494e406f840db1fa6d3d1188f7786a55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
